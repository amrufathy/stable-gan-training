{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "wgans.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vrnVC8TMrf4"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLAWAHxk8U0a"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as K\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "from IPython import display\n",
        "from pathlib import Path\n",
        "\n",
        "tf.random.set_seed(123)\n",
        "np.random.seed(123)\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rL9vKOLaNJBh"
      },
      "source": [
        "#@title Global Parameters\n",
        "\n",
        "BUFFER_SIZE = 10000\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 200\n",
        "noise_dim = 100\n",
        "num_examples_to_generate = 16\n",
        "image_size = 128"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmv1F1Nqdutd"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6M3gG5z6Dg_"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxRsRYVR6U5t"
      },
      "source": [
        "!cp '/content/gdrive/My Drive/img_align_celeba.zip' 'img_align_celeba.zip'\n",
        "!unzip -q img_align_celeba.zip\n",
        "!rm img_align_celeba.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeNrvS2F_dp1",
        "cellView": "both"
      },
      "source": [
        "#@title Load tf.dataset\n",
        "\n",
        "@tf.function\n",
        "def resize_image_keep_aspect(image):\n",
        "  s = tf.cast(tf.shape(image), tf.float32)\n",
        "  w, h = s[0], s[1]\n",
        "\n",
        "  min_dim = tf.minimum(w, h)\n",
        "  ratio = tf.cast(min_dim / image_size, tf.float32)\n",
        "\n",
        "  new_width = tf.cast(w / ratio, tf.int32)\n",
        "  new_height = tf.cast(h / ratio, tf.int32)\n",
        "\n",
        "  return tf.image.resize(image, [new_width, new_height])\n",
        "\n",
        "@tf.function\n",
        "def process_image(image_file):\n",
        "  # read image from file\n",
        "  image = tf.io.read_file(image_file)\n",
        "  image = tf.image.decode_jpeg(image)\n",
        "  image = tf.cast(image, tf.float32)\n",
        "\n",
        "  # resize\n",
        "  image = resize_image_keep_aspect(image)\n",
        "  \n",
        "  # random crop\n",
        "  image = tf.image.random_crop(image, size=[image_size, image_size, 3])\n",
        "\n",
        "  # normalize [-1, 1]\n",
        "  image = (image / 127.5) - 1\n",
        "\n",
        "  return image\n",
        "\n",
        "\n",
        "train_dataset = tf.data.Dataset.list_files('img_align_celeba/0[0-1]*.jpg').map(process_image).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "# train_dataset = tf.data.Dataset.list_files('images/*.jpg').flat_map(process_image).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "print(train_dataset.element_spec)\n",
        "print(tf.data.experimental.cardinality(train_dataset).numpy() * BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_DLDGqDUH7E",
        "cellView": "both"
      },
      "source": [
        "#@title Utilities\n",
        "\n",
        "def visualize_imgs(imgs, shape):\n",
        "  (row, col) = shape\n",
        "  (height, width) = imgs[0].shape[:2]\n",
        "  total_img = np.zeros((height * row, width * col, 3))\n",
        "  for idx, img in enumerate(imgs):\n",
        "    i, j = idx % col, idx // col\n",
        "    total_img[j*height:(j+1)*height, i*width:(i+1)*width, :] = img\n",
        "  return total_img\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgG816zcAfIC"
      },
      "source": [
        "#@title See Ground Truth\n",
        "\n",
        "batch = next(train_dataset.prefetch(1).as_numpy_iterator())\n",
        "batch = batch[:16, :, :, :]\n",
        "print(np.shape(batch))\n",
        "\n",
        "img = visualize_imgs(batch, (4, 4)) * 0.5 + 0.5\n",
        "plt.figure()\n",
        "plt.imshow(img)\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "plt.imsave(f'ground_truth.png', img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uggOvQDTrrY"
      },
      "source": [
        "#@title Load Pretrained weights\n",
        "\n",
        "!cp '/content/gdrive/My Drive/plots_imgs_loss.zip' 'plots_imgs_loss.zip'\n",
        "!unzip -q plots_imgs_loss.zip\n",
        "!rm plots_imgs_loss.zip\n",
        "\n",
        "!cp '/content/gdrive/My Drive/train_ckpts.zip' 'train_ckpts.zip'\n",
        "!unzip -q train_ckpts.zip\n",
        "!rm train_ckpts.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnw7h_F2tZ_k"
      },
      "source": [
        "# GAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpqvRSxdIzyl"
      },
      "source": [
        "Paper: https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPRgJFMdYYg7"
      },
      "source": [
        "bce = K.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "W_INIT = K.initializers.RandomNormal(stddev=0.02)\n",
        "G_INIT = K.initializers.RandomNormal(1.0, 0.02)\n",
        "\n",
        "class BaseGAN:\n",
        "  def __init__(self, load=True): \n",
        "    self.G = self.create_generator()\n",
        "    self.D = self.create_discriminator()\n",
        "\n",
        "    self.gen_update = K.optimizers.Adam(1e-4, beta_1=0.5)\n",
        "    self.disc_update = K.optimizers.Adam(1e-4, beta_1=0.5)\n",
        "\n",
        "    self.ckpt_prefix = f'training_checkpoints/{self.name}'\n",
        "    self.ckpt = tf.train.Checkpoint(generator_optimizer=self.gen_update,\n",
        "                                    discriminator_optimizer=self.disc_update,\n",
        "                                    generator=self.G,\n",
        "                                    discriminator=self.D)\n",
        "    \n",
        "    self.ckpt_manager = tf.train.CheckpointManager(self.ckpt, self.ckpt_prefix, max_to_keep=3)\n",
        "\n",
        "    if load: self.load()\n",
        "\n",
        "    Path(f'./figs/{self.name}').mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    self.global_g_loss, self.global_d_loss = [], []\n",
        "\n",
        "  @property\n",
        "  def name(self):\n",
        "    return str(type(self).__name__).lower()\n",
        "\n",
        "  def create_generator(self):\n",
        "    raise NotImplementedError\n",
        "\n",
        "  def create_discriminator(self):\n",
        "    raise NotImplementedError\n",
        "    \n",
        "  def discriminator_loss(self, real_output, fake_output, *args):\n",
        "    raise NotImplementedError\n",
        "  \n",
        "  def generator_loss(self, fake_output):\n",
        "    raise NotImplementedError\n",
        "\n",
        "  @tf.function\n",
        "  def train_step(self, images):\n",
        "    z = tf.random.normal([BATCH_SIZE, noise_dim])\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "      real_logits = self.D(images, training=True)\n",
        "      fake_logits = self.D(self.G(z, training=True), training=True)\n",
        "\n",
        "      gen_loss = self.generator_loss(fake_logits)\n",
        "      disc_loss = self.discriminator_loss(real_logits, fake_logits)\n",
        "\n",
        "    gen_grads = gen_tape.gradient(gen_loss, self.G.trainable_variables)\n",
        "    disc_grads = disc_tape.gradient(disc_loss, self.D.trainable_variables)\n",
        "\n",
        "    self.gen_update.apply_gradients(zip(gen_grads, self.G.trainable_variables))\n",
        "    self.disc_update.apply_gradients(zip(disc_grads, self.D.trainable_variables))\n",
        "\n",
        "    return gen_loss, disc_loss\n",
        "\n",
        "  def train(self, dataset, epochs, start_epoch=0):\n",
        "    seed = tf.random.normal([num_examples_to_generate, noise_dim])\n",
        "\n",
        "    for epoch in range(start_epoch, epochs):\n",
        "      g_loss, d_loss = [], []\n",
        "\n",
        "      for image_batch in dataset:\n",
        "        gl, dl = self.train_step(image_batch)\n",
        "        g_loss.append(gl.numpy())\n",
        "        d_loss.append(dl.numpy())\n",
        "\n",
        "      display.clear_output(wait=True)\n",
        "      \n",
        "      # Plot epoch loss\n",
        "      self.plot_epoch_loss(g_loss, d_loss, epoch + 1)\n",
        "      self.global_g_loss.extend(g_loss), self.global_d_loss.extend(d_loss)\n",
        "\n",
        "      # Produce images for the GIF as we go\n",
        "      self.generate_and_save_images(epoch + 1, seed)\n",
        "\n",
        "      # Save the model\n",
        "      self.ckpt_manager.save()\n",
        "\n",
        "    # Generate after the final epoch\n",
        "    display.clear_output(wait=True)\n",
        "    self.plot_epoch_loss(self.global_g_loss, self.global_d_loss, 0, 'Global Loss')\n",
        "    self.generate_and_save_images(epochs, seed)\n",
        "\n",
        "  def generate_and_save_images(self, epoch, test_input):\n",
        "    predictions = self.G(test_input, training=False)\n",
        "    img = visualize_imgs(predictions, (4, 4)) * 0.5 + 0.5\n",
        "\n",
        "    plt.figure()\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "    plt.imsave(f'figs/{self.name}/image_at_epoch_{epoch:04d}.png', img)\n",
        "\n",
        "  def plot_epoch_loss(self, G_losses, D_losses, epoch, title=''):\n",
        "    plt.figure(figsize=(6,3))\n",
        "    t = title if not title == '' else f'Generator and Discriminator Loss - Epoch {epoch}'\n",
        "    plt.title(t)\n",
        "    plt.plot(G_losses, label=\"G\")\n",
        "    plt.plot(D_losses, label=\"D\")\n",
        "    plt.xlabel(\"iterations\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "    plt.savefig(f'figs/{self.name}/loss_at_epoch_{epoch:04d}.png')\n",
        "\n",
        "  def load(self):\n",
        "    if self.ckpt_manager.latest_checkpoint:\n",
        "      self.ckpt.restore(self.ckpt_manager.latest_checkpoint)\n",
        "\n",
        "  def sample(self, save=False):\n",
        "    noise = tf.random.normal([1, 100])\n",
        "    generated_image = self.G(noise, training=False)\n",
        "    print(f'generated image shape: {np.shape(generated_image)}')\n",
        "\n",
        "    img = generated_image[0, :, :].numpy() * 0.5 + 0.5\n",
        "\n",
        "    plt.imshow(img)\n",
        "    if save: plt.imsave(f'{self.name}_sample.png', img)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    decision = self.D(generated_image)\n",
        "    print(f'decision: {decision}')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7Kse7C6sbhP"
      },
      "source": [
        "class GAN(BaseGAN):\n",
        "  def create_generator(self):\n",
        "    dim = image_size // 4 # 7\n",
        "    x_in = K.layers.Input(shape=(100,))\n",
        "\n",
        "    x = K.layers.Dense(1024, activation=tf.nn.relu, kernel_initializer=W_INIT)(x_in)\n",
        "    x = K.layers.Dense(1024, activation=tf.nn.relu, kernel_initializer=W_INIT)(x)\n",
        "    x = K.layers.Dense(1024, activation=tf.nn.relu, kernel_initializer=W_INIT)(x)\n",
        "    x = K.layers.Dense(image_size * image_size * 3, activation=tf.nn.tanh, kernel_initializer=W_INIT)(x)\n",
        "    x_out = K.layers.Reshape((image_size, image_size, 3))(x)\n",
        "    \n",
        "    assert x_out.shape[1:] == (image_size, image_size, 3)\n",
        "    \n",
        "    return K.Model(x_in, x_out)\n",
        "\n",
        "  def create_discriminator(self):\n",
        "    x_in = K.layers.Input(shape=(image_size, image_size, 3))\n",
        "    # x = K.layers.Reshape((image_size * image_size * 3))(x_in)\n",
        "    x = K.layers.Flatten()(x_in)\n",
        "    \n",
        "    x = K.layers.Dense(256, activation=tf.nn.relu, kernel_initializer=W_INIT)(x)\n",
        "    x = K.layers.Dense(256, activation=tf.nn.relu, kernel_initializer=W_INIT)(x)\n",
        "    x = K.layers.Dense(256, activation=tf.nn.relu, kernel_initializer=W_INIT)(x)\n",
        "    x_out = K.layers.Dense(1, kernel_initializer=W_INIT)(x)\n",
        "\n",
        "    return K.Model(x_in, x_out)\n",
        "    \n",
        "  def discriminator_loss(self, real_output, fake_output):\n",
        "    real_loss = bce(y_true=tf.ones_like(real_output), y_pred=real_output)\n",
        "    fake_loss = bce(y_true=tf.zeros_like(fake_output), y_pred=fake_output)\n",
        "    return real_loss + fake_loss\n",
        "  \n",
        "  def generator_loss(self, fake_output):\n",
        "    return bce(y_true=tf.ones_like(fake_output), y_pred=fake_output)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdYed80Qusk1"
      },
      "source": [
        "gan = GAN(load=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2ebZPwQuw-y"
      },
      "source": [
        "gan.sample(save=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wzy1lVGBwd6D"
      },
      "source": [
        "gan.train(train_dataset, EPOCHS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1rDuKw7EHuA"
      },
      "source": [
        "# DCGAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrZYD-ftJS4B"
      },
      "source": [
        "Paper: https://arxiv.org/pdf/1511.06434.pdf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwT4pk4v1YUy"
      },
      "source": [
        "# https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html\n",
        "# https://www.tensorflow.org/tutorials/generative/dcgan\n",
        "\n",
        "class DCGAN(GAN):\n",
        "  def create_generator(self):\n",
        "    dim = image_size // 16\n",
        "    x_in = K.layers.Input(shape=(100,))\n",
        "\n",
        "    x = K.layers.Dense(dim * dim * 512, use_bias=False)(x_in)\n",
        "    x = K.layers.Reshape((dim, dim, 512))(x)\n",
        "    x = K.layers.BatchNormalization(gamma_initializer=G_INIT)(x)\n",
        "    x = K.layers.ReLU()(x) # 8x8x512\n",
        "\n",
        "    x = K.layers.Conv2DTranspose(256, 5, strides=2, padding='same', use_bias=False, kernel_initializer=W_INIT)(x)\n",
        "    x = K.layers.BatchNormalization(gamma_initializer=G_INIT)(x)\n",
        "    x = K.layers.ReLU()(x) # 16x16x256\n",
        "\n",
        "    x = K.layers.Conv2DTranspose(128, 5, strides=2, padding='same', use_bias=False, kernel_initializer=W_INIT)(x)\n",
        "    x = K.layers.BatchNormalization(gamma_initializer=G_INIT)(x)\n",
        "    x = K.layers.ReLU()(x) # 32x32x128\n",
        "\n",
        "    x = K.layers.Conv2DTranspose(64, 5, strides=2, padding='same', use_bias=False, kernel_initializer=W_INIT)(x)\n",
        "    x = K.layers.BatchNormalization(gamma_initializer=G_INIT)(x)\n",
        "    x = K.layers.ReLU()(x) # 64x64x64\n",
        "\n",
        "    x_out = K.layers.Conv2DTranspose(3, 5, strides=2, padding='same', use_bias=False, \n",
        "                                     activation=tf.nn.tanh, kernel_initializer=W_INIT)(x) # 128x128x3\n",
        "    assert x_out.shape[1:] == (image_size, image_size, 3)\n",
        "    \n",
        "    return K.Model(x_in, x_out)\n",
        "\n",
        "  def create_discriminator(self):\n",
        "    x_in = K.layers.Input(shape=(image_size, image_size, 3)) # 128x128x3\n",
        "\n",
        "    x = K.layers.Conv2D(64, 5, strides=2, padding='same', kernel_initializer=W_INIT)(x_in)\n",
        "    x = K.layers.LeakyReLU(0.2)(x) # 64x64x64\n",
        "\n",
        "    x = K.layers.Conv2D(128, 5, strides=2, padding='same', kernel_initializer=W_INIT)(x)\n",
        "    x = K.layers.BatchNormalization(gamma_initializer=G_INIT)(x)\n",
        "    x = K.layers.LeakyReLU(0.2)(x) # 32x32x128\n",
        "\n",
        "    x = K.layers.Conv2D(256, 5, strides=2, padding='same', kernel_initializer=W_INIT)(x)\n",
        "    x = K.layers.BatchNormalization(gamma_initializer=G_INIT)(x)\n",
        "    x = K.layers.LeakyReLU(0.2)(x) # 16x16x256\n",
        "\n",
        "    x = K.layers.Conv2D(512, 5, strides=2, padding='same', kernel_initializer=W_INIT)(x)\n",
        "    x = K.layers.BatchNormalization(gamma_initializer=G_INIT)(x)\n",
        "    x = K.layers.LeakyReLU(0.2)(x) # 8x8x512\n",
        "\n",
        "    x = K.layers.Flatten()(x)\n",
        "    x_out = K.layers.Dense(1, kernel_initializer=W_INIT)(x)\n",
        "\n",
        "    return K.Model(x_in, x_out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nf0Rk5aG10eP"
      },
      "source": [
        "dcgan = DCGAN(load=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1w82dvH12IZ"
      },
      "source": [
        "dcgan.sample(save=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tg9H4thL127X"
      },
      "source": [
        "dcgan.train(train_dataset, EPOCHS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ykik_FUAdgSG"
      },
      "source": [
        "# WGAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVh9pHhRJbey"
      },
      "source": [
        "Paper: https://arxiv.org/pdf/1701.07875.pdf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cC-xhngU4qUW"
      },
      "source": [
        "# https://github.com/hcnoh/WGAN-tensorflow2/blob/master/train.py#L78\n",
        "\n",
        "class WGAN(DCGAN):\n",
        "  def __init__(self, load=True):\n",
        "    super().__init__(load)\n",
        "\n",
        "    # self.gen_update = K.optimizers.Adam(1e-4, beta_1=0.5)\n",
        "    self.gen_update = K.optimizers.RMSprop(0.00005)\n",
        "    # self.disc_update = K.optimizers.Adam(1e-4, beta_1=0.5)\n",
        "    self.disc_update = K.optimizers.RMSprop(0.00005)\n",
        "\n",
        "  def discriminator_loss(self, real_output, fake_output):\n",
        "    real_loss = tf.reduce_mean(real_output)\n",
        "    fake_loss = tf.reduce_mean(fake_output)\n",
        "    return fake_loss - real_loss\n",
        "  \n",
        "  def generator_loss(self, fake_output):\n",
        "    return -tf.reduce_mean(fake_output)\n",
        "\n",
        "  @tf.function\n",
        "  def train_step(self, images):\n",
        "    z = tf.random.normal([BATCH_SIZE, noise_dim])\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "      real_logits = self.D(images, training=True)\n",
        "      fake_logits = self.D(self.G(z, training=True), training=True)\n",
        "\n",
        "      gen_loss = self.generator_loss(fake_logits)\n",
        "      disc_loss = self.discriminator_loss(real_logits, fake_logits)\n",
        "\n",
        "    gen_grads = gen_tape.gradient(gen_loss, self.G.trainable_variables)\n",
        "    disc_grads = disc_tape.gradient(disc_loss, self.D.trainable_variables)\n",
        "\n",
        "    self.gen_update.apply_gradients(zip(gen_grads, self.G.trainable_variables))\n",
        "    self.disc_update.apply_gradients(zip(disc_grads, self.D.trainable_variables))\n",
        "\n",
        "    for var in self.D.trainable_variables:\n",
        "      var.assign(tf.clip_by_value(var, -0.1, 0.1))\n",
        "\n",
        "    return gen_loss, disc_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWcclSvN7Hho"
      },
      "source": [
        "wgan = WGAN(load=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3x06KHMS7KnM"
      },
      "source": [
        "wgan.sample(save=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Frx2Vpzv7LF-"
      },
      "source": [
        "wgan.train(train_dataset, EPOCHS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StVB-bpv6u-A"
      },
      "source": [
        "# WGAN &mdash; GP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jj65mxbPJnMq"
      },
      "source": [
        "Paper: https://arxiv.org/pdf/1704.00028.pdf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-udoXw3I8wYc"
      },
      "source": [
        "# https://github.com/KUASWoodyLIN/TF2-WGAN/blob/master/utils/losses.py\n",
        "class WGANGP(DCGAN):\n",
        "  def discriminator_loss(self, real_output, fake_output, images_real, images_fake):\n",
        "    images_real = tf.squeeze(images_real)\n",
        "    images_fake = images_fake[:tf.shape(images_real)[0], :, :]\n",
        "\n",
        "    def _interpolate(a, b):\n",
        "        shape = [tf.shape(a)[0]] + [1] * (a.shape.ndims - 1)\n",
        "        alpha = tf.random.uniform(shape=shape, minval=0., maxval=1.)\n",
        "        inter = (alpha * a) + ((1 - alpha) * b)\n",
        "        inter.set_shape(a.shape)\n",
        "        return inter\n",
        "\n",
        "    x = _interpolate(images_real, images_fake)\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(x)\n",
        "        pred = self.D(x)\n",
        "    grad = tape.gradient(pred, x)\n",
        "    norm = tf.norm(tf.reshape(grad, [tf.shape(grad)[0], -1]), axis=1)\n",
        "    gp = 10 * tf.reduce_mean((norm - 1.) ** 2)\n",
        "    \n",
        "    real_loss = tf.reduce_mean(real_output)\n",
        "    fake_loss = tf.reduce_mean(fake_output)\n",
        "    \n",
        "    return fake_loss - real_loss + gp\n",
        "\n",
        "  def generator_loss(self, fake_output):\n",
        "    return -tf.reduce_mean(fake_output)\n",
        "\n",
        "  @tf.function\n",
        "  def train_step(self, images):\n",
        "    z = tf.random.normal([BATCH_SIZE, noise_dim])\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "      images_fake = self.G(z, training=True)\n",
        "      real_logits = self.D(images, training=True)\n",
        "      fake_logits = self.D(images_fake, training=True)\n",
        "\n",
        "      gen_loss = self.generator_loss(fake_logits)\n",
        "      disc_loss = self.discriminator_loss(real_logits, fake_logits, images, images_fake)\n",
        "\n",
        "    gen_grads = gen_tape.gradient(gen_loss, self.G.trainable_variables)\n",
        "    disc_grads = disc_tape.gradient(disc_loss, self.D.trainable_variables)\n",
        "\n",
        "    self.gen_update.apply_gradients(zip(gen_grads, self.G.trainable_variables))\n",
        "    self.disc_update.apply_gradients(zip(disc_grads, self.D.trainable_variables))\n",
        "\n",
        "    return gen_loss, disc_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbxUo8IDu4ut"
      },
      "source": [
        "wgangp = WGANGP(load=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzpY_yuKu8L_"
      },
      "source": [
        "wgangp.sample(save=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_9lphymu9qZ"
      },
      "source": [
        "wgangp.train(train_dataset, 100, start_epoch=50) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PgQpmL0DDgyd"
      },
      "source": [
        "# Save Weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I01Tp4eVhpmf"
      },
      "source": [
        "!zip -qr plots_imgs_loss.zip figs\n",
        "!cp 'plots_imgs_loss.zip' '/content/gdrive/My Drive/plots_imgs_loss.zip'\n",
        "!rm plots_imgs_loss.zip\n",
        "\n",
        "!zip -qr train_ckpts.zip training_checkpoints\n",
        "!cp 'train_ckpts.zip' '/content/gdrive/My Drive/train_ckpts.zip'\n",
        "!rm train_ckpts.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCFdG5stDrHL"
      },
      "source": [
        "# Create GIF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PZpuzb7Duk0"
      },
      "source": [
        "!pip install -q imageio\n",
        "\n",
        "import imageio\n",
        "import glob\n",
        "from google.colab import files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-pBJ8F2DwGa"
      },
      "source": [
        "model = 'wgangp'\n",
        "anim_file = f'{model}.gif'\n",
        "\n",
        "with imageio.get_writer(anim_file, mode='I') as writer:\n",
        "  filenames = glob.glob(f'figs/{model}/image*.png')\n",
        "  filenames = sorted(filenames)\n",
        "  last = -1\n",
        "  for i,filename in enumerate(filenames):\n",
        "    frame = 2*(i**0.5)\n",
        "    if round(frame) > round(last):\n",
        "      last = frame\n",
        "    else:\n",
        "      continue\n",
        "    image = imageio.imread(filename)\n",
        "    writer.append_data(image)\n",
        "  image = imageio.imread(filename)\n",
        "  writer.append_data(image)\n",
        "\n",
        "files.download(anim_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79fA4VWr5tK7"
      },
      "source": [
        "# WGAN &mdash; CT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhpX7C_e5xGP"
      },
      "source": [
        "Paper: https://arxiv.org/pdf/1803.01541.pdf"
      ]
    }
  ]
}